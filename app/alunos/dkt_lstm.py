import json
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple, Optional
import argparse
from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, roc_curve
from sklearn.preprocessing import LabelEncoder
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import warnings
warnings.filterwarnings('ignore')

# Configurar estilo dos gr√°ficos
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# Configurar seed para reprodutibilidade
torch.manual_seed(42)
np.random.seed(42)

class DKTDataset(Dataset):
    """
    Dataset para DKT multitarefa com alvos de regress√£o e classifica√ß√£o
    """
    def __init__(self, sequences: List[np.ndarray], targets_reg: List[float], targets_cls: List[int]):
        self.sequences = sequences
        self.targets_reg = targets_reg  # float - valores cont√≠nuos
        self.targets_cls = targets_cls  # int - 0/1
    
    def __len__(self):
        return len(self.sequences)
    
    def __getitem__(self, idx):
        x = torch.FloatTensor(self.sequences[idx])
        y_reg = torch.FloatTensor([self.targets_reg[idx]])
        y_cls = torch.FloatTensor([self.targets_cls[idx]])
        return x, y_reg.squeeze(), y_cls.squeeze()

class DKTModel(nn.Module):
    """
    Modelo DKT multitarefa usando LSTM com dois heads: regress√£o e classifica√ß√£o
    """
    def __init__(self, input_size: int, hidden_size: int = 128, num_layers: int = 2, 
                 dropout: float = 0.3):
        super(DKTModel, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTM compartilhado
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout if num_layers > 1 else 0,
            batch_first=True,
            bidirectional=False
        )
        
        # Dropout compartilhado
        self.dropout = nn.Dropout(dropout)
        
        # Heads separados
        self.fc_reg = nn.Linear(hidden_size, 1)   # regress√£o (cont√≠nuo)
        self.fc_cls = nn.Linear(hidden_size, 1)   # classifica√ß√£o (logit)
        
    def forward(self, x: torch.Tensor):
        # x shape: (batch_size, seq_len, input_size)
        lstm_out, _ = self.lstm(x)
        
        # Pegar apenas o √∫ltimo output da sequ√™ncia
        h_last = lstm_out[:, -1, :]
        h_last = self.dropout(h_last)
        
        # Head de regress√£o (com limita√ß√£o a 1.0)
        y_reg = self.fc_reg(h_last).squeeze(-1)
        y_reg = torch.clamp(y_reg, -1.0, 1.0)  # Limitar entre -1 e 1
        
        # Head de classifica√ß√£o (logit + sigmoid)
        y_logit = self.fc_cls(h_last).squeeze(-1)
        y_prob = torch.sigmoid(y_logit)
        
        return y_reg, y_logit, y_prob

def carregar_dados_aluno(student_id: int, dias: int = 20, pasta_output: str = "output") -> List[Dict]:
    """
    Carrega dados de um aluno espec√≠fico
    """
    pasta_aluno = os.path.join(pasta_output, f"aluno_{student_id}")
    
    if not os.path.exists(pasta_aluno):
        raise FileNotFoundError(f"Pasta do aluno {student_id} n√£o encontrada: {pasta_aluno}")
    
    dados = []
    for dia in range(1, dias + 1):
        arquivo = os.path.join(pasta_aluno, f"desempenho_dia_{dia}.json")
        
        if not os.path.exists(arquivo):
            print(f"‚ö†Ô∏è  Arquivo do dia {dia} n√£o encontrado, parando em {len(dados)} dias")
            break
        
        with open(arquivo, 'r', encoding='utf-8') as f:
            dados_dia = json.load(f)
            dados.append(dados_dia)
    
    print(f"üìä Carregados {len(dados)} dias de dados para aluno {student_id}")
    return dados

def preparar_dados_dkt(dados: List[Dict], window_size: int = 5, dias_treino: int = 60, normalizar: bool = True) -> Tuple[List[np.ndarray], List[float], List[int], List[np.ndarray], List[float], List[int], Dict]:
    """
    Prepara dados para DKT criando sequ√™ncias temporais
    Separa dados de treino (60 dias) e teste (5 dias)
    """
    print("üîÑ Preparando dados para DKT...")
    
    # Separar dados de treino e teste
    dados_treino = dados[:dias_treino]
    dados_teste = dados[dias_treino:]
    
    # Calcular estat√≠sticas para normaliza√ß√£o (apenas com dados de treino)
    if normalizar:
        print("   üîß Calculando estat√≠sticas para normaliza√ß√£o...")
        todas_features_treino = []
        for dados_dia in dados_treino:
            for item in dados_dia:
                feature_vector = [
                    item['desempenho'],
                    item['peso_classe'],
                    item['peso_subclasse'], 
                    item['peso_por_questao']
                ]
                todas_features_treino.append(feature_vector)
        
        todas_features_treino = np.array(todas_features_treino)
        feature_means = np.mean(todas_features_treino, axis=0)
        feature_stds = np.std(todas_features_treino, axis=0)
        feature_stds = np.where(feature_stds == 0, 1.0, feature_stds)  # Evitar divis√£o por zero
        
        normalizacao_stats = {
            'means': feature_means.tolist(),
            'stds': feature_stds.tolist()
        }
        print(f"   üìä Estat√≠sticas de normaliza√ß√£o calculadas")
    else:
        normalizacao_stats = None
    
    print(f"   üìä Dados de treino: {len(dados_treino)} dias")
    print(f"   üìä Dados de teste: {len(dados_teste)} dias")
    print(f"   üìä Configura√ß√£o: {dias_treino} dias treino + {len(dados_teste)} dias teste = {len(dados)} dias total")
    
    # Preparar dados de treino
    features_treino = []
    targets_reg_treino = []  # Alvos de regress√£o (cont√≠nuos)
    targets_cls_treino = []  # Alvos de classifica√ß√£o (bin√°rios)
    
    for dia_idx, dados_dia in enumerate(dados_treino):
        # Features do dia atual
        features_dia = []
        
        for item in dados_dia:
            # Features: desempenho, peso_classe, peso_subclasse, peso_por_questao
            feature_vector = [
                item['desempenho'],
                item['peso_classe'],
                item['peso_subclasse'], 
                item['peso_por_questao']
            ]
            
            # Aplicar normaliza√ß√£o se habilitada
            if normalizar and normalizacao_stats is not None:
                feature_vector = (np.array(feature_vector) - normalizacao_stats['means']) / normalizacao_stats['stds']
            
            features_dia.append(feature_vector)
        
        # Converter para array
        features_array = np.array(features_dia)
        features_treino.append(features_array)
        
        # Target de regress√£o: m√©dia do desempenho do pr√≥ximo dia (se existir)
        if dia_idx < len(dados_treino) - 1:
            # Calcular target baseado no pr√≥ximo dia
            proximo_dia = dados_treino[dia_idx + 1]
            desempenhos_proximo = [item['desempenho'] for item in proximo_dia]
            target_reg = np.mean(desempenhos_proximo)
        else:
            # Para o √∫ltimo dia, usar o pr√≥prio desempenho m√©dio
            desempenhos_atual = [item['desempenho'] for item in dados_dia]
            target_reg = np.mean(desempenhos_atual)
        
        # Target de classifica√ß√£o: se o pr√≥ximo dia tem desempenho > percentil 60 (crit√©rio mais balanceado)
        if dia_idx < len(dados_treino) - 1:
            proximo_dia = dados_treino[dia_idx + 1]
            desempenhos_proximo = [item['desempenho'] for item in proximo_dia]
            media_proximo = np.mean(desempenhos_proximo)
            
            # Calcular percentil 60 de todos os dias para usar como threshold
            todas_medias = []
            for dados_dia_geral in dados_treino:
                desempenhos_dia = [item['desempenho'] for item in dados_dia_geral]
                todas_medias.append(np.mean(desempenhos_dia))
            threshold_percentil = np.percentile(todas_medias, 60)
            
            target_cls = 1 if media_proximo > threshold_percentil else 0
        else:
            desempenhos_atual = [item['desempenho'] for item in dados_dia]
            media_atual = np.mean(desempenhos_atual)
            
            # Calcular percentil 60 de todos os dias para usar como threshold
            todas_medias = []
            for dados_dia_geral in dados_treino:
                desempenhos_dia = [item['desempenho'] for item in dados_dia_geral]
                todas_medias.append(np.mean(desempenhos_dia))
            threshold_percentil = np.percentile(todas_medias, 60)
            
            target_cls = 1 if media_atual > threshold_percentil else 0
        
        targets_reg_treino.append(target_reg)
        targets_cls_treino.append(target_cls)
    
    # Criar sequ√™ncias de treino com janela deslizante
    sequences_treino = []
    targets_reg_sequences = []
    targets_cls_sequences = []
    
    for i in range(len(features_treino) - window_size + 1):
        # Sequ√™ncia de features
        seq = features_treino[i:i + window_size]
        # Padronizar tamanho da sequ√™ncia (m√©dia dos conte√∫dos por dia)
        seq_padded = []
        for dia_features in seq:
            # Usar m√©dia das features do dia
            dia_avg = np.mean(dia_features, axis=0)
            seq_padded.append(dia_avg)
        
        sequences_treino.append(np.array(seq_padded))
        targets_reg_sequences.append(targets_reg_treino[i + window_size - 1])
        targets_cls_sequences.append(targets_cls_treino[i + window_size - 1])
    
    # Preparar dados de teste (usar √∫ltima sequ√™ncia de treino para prever pr√≥ximos dias)
    features_teste = []
    targets_reg_teste = []
    targets_cls_teste = []
    
    for dia_idx, dados_dia in enumerate(dados_teste):
        # Features do dia atual
        features_dia = []
        
        for item in dados_dia:
            feature_vector = [
                item['desempenho'],
                item['peso_classe'],
                item['peso_subclasse'], 
                item['peso_por_questao']
            ]
            
            # Aplicar normaliza√ß√£o se habilitada (usando estat√≠sticas do treino)
            if normalizar and normalizacao_stats is not None:
                feature_vector = (np.array(feature_vector) - normalizacao_stats['means']) / normalizacao_stats['stds']
            
            features_dia.append(feature_vector)
        
        features_array = np.array(features_dia)
        features_teste.append(features_array)
        
        # Target de regress√£o: m√©dia do desempenho do dia atual
        desempenhos_atual = [item['desempenho'] for item in dados_dia]
        target_reg = np.mean(desempenhos_atual)
        
        # Target de classifica√ß√£o: se o dia atual tem desempenho > percentil 60 (crit√©rio mais balanceado)
        # Calcular percentil 60 de todos os dias de treino para usar como threshold
        todas_medias_treino = []
        for dados_dia_geral in dados_treino:
            desempenhos_dia = [item['desempenho'] for item in dados_dia_geral]
            todas_medias_treino.append(np.mean(desempenhos_dia))
        threshold_percentil = np.percentile(todas_medias_treino, 60)
        
        target_cls = 1 if target_reg > threshold_percentil else 0
        
        targets_reg_teste.append(target_reg)
        targets_cls_teste.append(target_cls)
    
    print(f"   üìä Criadas {len(sequences_treino)} sequ√™ncias de treino com janela de {window_size} dias")
    print(f"   üéØ Features por sequ√™ncia: {sequences_treino[0].shape}")
    print(f"   üìä Dados de teste: {len(targets_reg_teste)} dias para previs√£o (limitado a 5 dias)")
    
    # Mostrar distribui√ß√£o das classes
    targets_cls_array = np.array(targets_cls_sequences)
    targets_cls_teste_array = np.array(targets_cls_teste)
    
    print(f"   üìà Distribui√ß√£o das classes:")
    print(f"      üéØ Treino - Classe 0: {np.sum(targets_cls_array == 0)} ({np.mean(targets_cls_array == 0)*100:.1f}%)")
    print(f"      üéØ Treino - Classe 1: {np.sum(targets_cls_array == 1)} ({np.mean(targets_cls_array == 1)*100:.1f}%)")
    print(f"      üîÆ Teste - Classe 0: {np.sum(targets_cls_teste_array == 0)} ({np.mean(targets_cls_teste_array == 0)*100:.1f}%)")
    print(f"      üîÆ Teste - Classe 1: {np.sum(targets_cls_teste_array == 1)} ({np.mean(targets_cls_teste_array == 1)*100:.1f}%)")
    
    return sequences_treino, targets_reg_sequences, targets_cls_sequences, features_teste, targets_reg_teste, targets_cls_teste, normalizacao_stats

def treinar_modelo_dkt(sequences: List[np.ndarray], targets_reg: List[float], targets_cls: List[int],
                      input_size: int = 4, hidden_size: int = 64, num_layers: int = 2,
                      learning_rate: float = 0.001, epochs: int = 100, 
                      batch_size: int = 8, alpha: float = 1.0, beta: float = 0.7,
                      patience: int = 10, val_split: float = 0.2) -> Tuple[DKTModel, List[float]]:
    """
    Treina o modelo DKT
    """
    print("üöÄ Treinando modelo DKT...")
    
    # Criar dataset e dataloader
    dataset = DKTDataset(sequences, targets_reg, targets_cls)
    
    # Split treino/valida√ß√£o
    val_size = int(len(dataset) * val_split)
    train_size = len(dataset) - val_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    print(f"   üìä Split treino/valida√ß√£o: {train_size}/{val_size} amostras")
    
    # Inicializar modelo
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"   üîß Usando dispositivo: {device}")
    
    model = DKTModel(
        input_size=input_size,
        hidden_size=hidden_size,
        num_layers=num_layers
    ).to(device)
    
    # Loss functions
    bce_loss = nn.BCEWithLogitsLoss()  # Para classifica√ß√£o (usa logit)
    mse_loss = nn.MSELoss()  # Para regress√£o
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    print(f"   üéØ Perda combinada: Œ±={alpha}*BCE + Œ≤={beta}*MSE")
    
    # Treinamento com early stopping
    losses = []
    val_aucs = []
    best_val_auc = 0.0
    best_model_state = None
    patience_counter = 0
    
    print(f"   üéØ Early stopping: patience={patience}, monitorando AUC de valida√ß√£o")
    
    for epoch in range(epochs):
        # Treinamento
        model.train()
        epoch_loss = 0.0
        
        for batch_sequences, batch_targets_reg, batch_targets_cls in train_dataloader:
            batch_sequences = batch_sequences.to(device)
            batch_targets_reg = batch_targets_reg.to(device)
            batch_targets_cls = batch_targets_cls.to(device)
            
            # Forward pass
            y_reg_hat, y_logit, y_prob = model(batch_sequences)
            
            # Calcular perdas
            loss_cls = bce_loss(y_logit, batch_targets_cls)
            loss_reg = mse_loss(y_reg_hat, batch_targets_reg)
            
            # Perda combinada
            loss = alpha * loss_cls + beta * loss_reg
            
            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
        
        avg_loss = epoch_loss / len(train_dataloader)
        losses.append(avg_loss)
        
        # Valida√ß√£o
        model.eval()
        val_predictions = []
        val_targets = []
        
        with torch.no_grad():
            for batch_sequences, batch_targets_reg, batch_targets_cls in val_dataloader:
                batch_sequences = batch_sequences.to(device)
                batch_targets_cls = batch_targets_cls.to(device)
                
                y_reg_hat, y_logit, y_prob = model(batch_sequences)
                val_predictions.extend(y_prob.cpu().numpy())
                val_targets.extend(batch_targets_cls.cpu().numpy())
        
        # Calcular AUC de valida√ß√£o
        try:
            from sklearn.metrics import roc_auc_score
            val_auc = roc_auc_score(val_targets, val_predictions)
        except ValueError:
            val_auc = 0.5  # Valor neutro se h√° apenas uma classe
        
        val_aucs.append(val_auc)
        
        # Early stopping
        if val_auc > best_val_auc:
            best_val_auc = val_auc
            best_model_state = model.state_dict().copy()
            patience_counter = 0
        else:
            patience_counter += 1
        
        if (epoch + 1) % 20 == 0:
            print(f"   üìà √âpoca {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}, Val AUC: {val_auc:.4f}")
        
        # Parar se n√£o melhorou por 'patience' √©pocas
        if patience_counter >= patience:
            print(f"   üõë Early stopping na √©poca {epoch + 1} (melhor Val AUC: {best_val_auc:.4f})")
            break
    
    # Carregar melhor modelo
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
        print(f"   ‚úÖ Melhor modelo carregado (Val AUC: {best_val_auc:.4f})")
    
    print(f"‚úÖ Treinamento conclu√≠do!")
    return model, losses

def avaliar_modelo_dkt(model: DKTModel, sequences_treino: List[np.ndarray], targets_reg_treino: List[float], targets_cls_treino: List[int],
                      features_teste: List[np.ndarray], targets_reg_teste: List[float], targets_cls_teste: List[int],
                      batch_size: int = 8, calibrar: bool = True) -> Dict[str, float]:
    """
    Avalia o modelo DKT e faz previs√µes futuras
    """
    print("üìä Avaliando modelo...")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()
    
    # 1. Avaliar no conjunto de treino
    dataset_treino = DKTDataset(sequences_treino, targets_reg_treino, targets_cls_treino)
    dataloader_treino = DataLoader(dataset_treino, batch_size=batch_size, shuffle=False)
    
    all_predictions_reg_treino = []
    all_predictions_cls_treino = []
    all_targets_reg_treino = []
    all_targets_cls_treino = []
    
    with torch.no_grad():
        for batch_sequences, batch_targets_reg, batch_targets_cls in dataloader_treino:
            batch_sequences = batch_sequences.to(device)
            
            y_reg_hat, y_logit, y_prob = model(batch_sequences)
            
            all_predictions_reg_treino.extend(y_reg_hat.cpu().numpy())
            all_predictions_cls_treino.extend(y_prob.cpu().numpy())
            all_targets_reg_treino.extend(batch_targets_reg.numpy())
            all_targets_cls_treino.extend(batch_targets_cls.numpy())
    
    # 2. Fazer previs√µes futuras
    print("üîÆ Fazendo previs√µes futuras...")
    
    # Usar a √∫ltima sequ√™ncia de treino para prever os pr√≥ximos dias
    ultima_sequencia = sequences_treino[-1]  # √öltima sequ√™ncia de treino
    
    previsoes_reg_futuras = []
    previsoes_cls_futuras = []
    sequencia_atual = ultima_sequencia.copy()
    
    for dia_teste in range(len(targets_reg_teste)):
        # Converter para tensor
        input_tensor = torch.FloatTensor(sequencia_atual).unsqueeze(0).to(device)
        
        # Fazer previs√£o
        with torch.no_grad():
            y_reg_hat, y_logit, y_prob = model(input_tensor)
            previsao_reg = y_reg_hat.cpu().numpy()
            previsao_cls = y_prob.cpu().numpy()
        
        previsoes_reg_futuras.append(previsao_reg)
        previsoes_cls_futuras.append(previsao_cls)
        
        # Atualizar sequ√™ncia (remover primeiro dia, adicionar previs√£o)
        # Para simplificar, vamos usar a m√©dia das features do dia atual
        features_dia_atual = features_teste[dia_teste]
        media_features = np.mean(features_dia_atual, axis=0)
        
        # Atualizar sequ√™ncia
        sequencia_atual = np.vstack([sequencia_atual[1:], media_features.reshape(1, -1)])
    
    # Converter para arrays
    y_pred_reg_treino = np.array(all_predictions_reg_treino)
    y_true_reg_treino = np.array(all_targets_reg_treino)
    y_pred_cls_treino = np.array(all_predictions_cls_treino)
    y_true_cls_treino = np.array(all_targets_cls_treino)
    
    y_pred_reg_futuro = np.array(previsoes_reg_futuras)
    y_true_reg_futuro = np.array(targets_reg_teste)
    y_pred_cls_futuro = np.array(previsoes_cls_futuras)
    y_true_cls_futuro = np.array(targets_cls_teste)
    
    # Calibra√ß√£o das probabilidades (Platt Scaling)
    if calibrar:
        print("   üîß Aplicando calibra√ß√£o Platt Scaling...")
        try:
            from sklearn.linear_model import LogisticRegression
            from sklearn.calibration import CalibratedClassifierCV
            
            # Treinar calibrador com dados de treino
            base_classifier = LogisticRegression(random_state=42)
            base_classifier.fit(y_pred_cls_treino.reshape(-1, 1), y_true_cls_treino)
            
            calibrador = CalibratedClassifierCV(
                base_classifier, 
                cv='prefit', 
                method='sigmoid'
            )
            
            # Reshape para o formato esperado
            X_calib = y_pred_cls_treino.reshape(-1, 1)
            y_calib = y_true_cls_treino
            
            # Treinar calibrador
            calibrador.fit(X_calib, y_calib)
            
            # Aplicar calibra√ß√£o
            y_pred_cls_treino_calib = calibrador.predict_proba(X_calib)[:, 1]
            y_pred_cls_futuro_calib = calibrador.predict_proba(y_pred_cls_futuro.reshape(-1, 1))[:, 1]
            
            # Usar probabilidades calibradas
            y_pred_cls_treino = y_pred_cls_treino_calib
            y_pred_cls_futuro = y_pred_cls_futuro_calib
            
            print("   ‚úÖ Calibra√ß√£o aplicada com sucesso")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erro na calibra√ß√£o: {e}. Usando probabilidades originais.")
    else:
        print("   ‚è≠Ô∏è  Calibra√ß√£o desabilitada")
    
    # Calcular m√©tricas de regress√£o
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    
    # M√©tricas de regress√£o - treino
    mse_treino = mean_squared_error(y_true_reg_treino, y_pred_reg_treino)
    mae_treino = mean_absolute_error(y_true_reg_treino, y_pred_reg_treino)
    r2_treino = r2_score(y_true_reg_treino, y_pred_reg_treino)
    
    # M√©tricas de regress√£o - previs√£o futura
    mse_futuro = mean_squared_error(y_true_reg_futuro, y_pred_reg_futuro)
    mae_futuro = mean_absolute_error(y_true_reg_futuro, y_pred_reg_futuro)
    r2_futuro = r2_score(y_true_reg_futuro, y_pred_reg_futuro)
    
    # Calcular m√©tricas de classifica√ß√£o (alvos distintos)
    from sklearn.metrics import roc_auc_score, accuracy_score, log_loss
    
    # M√©tricas de classifica√ß√£o - treino
    try:
        auc_treino = roc_auc_score(y_true_cls_treino, y_pred_cls_treino)
    except ValueError:
        auc_treino = 0.5  # Valor neutro se h√° apenas uma classe
    
    try:
        accuracy_treino = accuracy_score(y_true_cls_treino, y_pred_cls_treino > 0.5)
    except ValueError:
        accuracy_treino = 1.0  # Se h√° apenas uma classe, accuracy √© 1.0
    
    try:
        logloss_treino = log_loss(y_true_cls_treino, y_pred_cls_treino)
    except ValueError:
        logloss_treino = 0.0  # Se h√° apenas uma classe, logloss √© 0.0
    
    # M√©tricas de classifica√ß√£o - futuro
    try:
        auc_futuro = roc_auc_score(y_true_cls_futuro, y_pred_cls_futuro)
    except ValueError:
        auc_futuro = 0.5  # Valor neutro se h√° apenas uma classe
    
    try:
        accuracy_futuro = accuracy_score(y_true_cls_futuro, y_pred_cls_futuro > 0.5)
    except ValueError:
        accuracy_futuro = 1.0  # Se h√° apenas uma classe, accuracy √© 1.0
    
    try:
        logloss_futuro = log_loss(y_true_cls_futuro, y_pred_cls_futuro)
    except ValueError:
        logloss_futuro = 0.0  # Se h√° apenas uma classe, logloss √© 0.0
    
    metrics = {
        # M√©tricas de regress√£o
        'mse_treino': mse_treino,
        'mae_treino': mae_treino,
        'r2_treino': r2_treino,
        'mse_futuro': mse_futuro,
        'mae_futuro': mae_futuro,
        'r2_futuro': r2_futuro,
        # M√©tricas de classifica√ß√£o
        'auc_treino': auc_treino,
        'accuracy_treino': accuracy_treino,
        'logloss_treino': logloss_treino,
        'auc_futuro': auc_futuro,
        'accuracy_futuro': accuracy_futuro,
        'logloss_futuro': logloss_futuro
    }
    
    print(f"   üìà Regress√£o - Treino: MSE={mse_treino:.4f}, MAE={mae_treino:.4f}, R¬≤={r2_treino:.4f}")
    print(f"   üîÆ Regress√£o - Futuro: MSE={mse_futuro:.4f}, MAE={mae_futuro:.4f}, R¬≤={r2_futuro:.4f}")
    print(f"   üéØ Classifica√ß√£o - Treino: AUC={auc_treino:.4f}, Accuracy={accuracy_treino:.4f}, LogLoss={logloss_treino:.4f}")
    print(f"   üéØ Classifica√ß√£o - Futuro: AUC={auc_futuro:.4f}, Accuracy={accuracy_futuro:.4f}, LogLoss={logloss_futuro:.4f}")
    
    return metrics, y_pred_reg_treino, y_true_reg_treino, y_pred_cls_treino, y_true_cls_treino, y_pred_reg_futuro, y_true_reg_futuro, y_pred_cls_futuro, y_true_cls_futuro

def plotar_resultados(losses: List[float], y_pred_reg_treino: np.ndarray, y_true_reg_treino: np.ndarray,
                     y_pred_cls_treino: np.ndarray, y_true_cls_treino: np.ndarray,
                     y_pred_reg_futuro: np.ndarray, y_true_reg_futuro: np.ndarray,
                     y_pred_cls_futuro: np.ndarray, y_true_cls_futuro: np.ndarray,
                     metrics: Dict[str, float], pasta_saida: str = "resultados_dkt"):
    """
    Plota resultados do treinamento, avalia√ß√£o e previs√µes futuras
    """
    print("üìä Gerando gr√°ficos...")
    
    if not os.path.exists(pasta_saida):
        os.makedirs(pasta_saida)
    
    # Criar figura com subplots (2x3 para acomodar mais gr√°ficos)
    fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 12))
    fig.suptitle('üß† DKT - Resultados de Treinamento e Previs√µes', fontsize=16, fontweight='bold')
    
    # Gr√°fico 1: Loss durante treinamento
    ax1.plot(losses, 'b-', linewidth=2, alpha=0.8)
    ax1.set_xlabel('√âpoca')
    ax1.set_ylabel('Loss')
    ax1.set_title('Loss durante Treinamento')
    ax1.grid(True, alpha=0.3)
    
    # Gr√°fico 2: Predi√ß√µes vs Valores Reais (Regress√£o - Treino)
    ax2.scatter(y_true_reg_treino, y_pred_reg_treino, alpha=0.7, color='#FF6B6B', label='Regress√£o')
    ax2.plot([y_true_reg_treino.min(), y_true_reg_treino.max()], [y_true_reg_treino.min(), y_true_reg_treino.max()], 'k--', alpha=0.5)
    ax2.set_xlabel('Valor Real')
    ax2.set_ylabel('Predi√ß√£o')
    ax2.set_title(f'Regress√£o - Treino (R¬≤ = {metrics["r2_treino"]:.3f})')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Gr√°fico 3: Previs√µes Futuras vs Valores Reais (Regress√£o)
    dias_futuros = list(range(1, len(y_pred_reg_futuro) + 1))
    ax3.plot(dias_futuros, y_true_reg_futuro, 'o-', linewidth=2, markersize=8, 
             color='#4ECDC4', label='Valor Real', alpha=0.8)
    ax3.plot(dias_futuros, y_pred_reg_futuro, 's-', linewidth=2, markersize=8, 
             color='#FF6B6B', label='Previs√£o DKT', alpha=0.8)
    ax3.set_xlabel('Dia Futuro')
    ax3.set_ylabel('Desempenho')
    ax3.set_title(f'Regress√£o - Futuro (R¬≤ = {metrics["r2_futuro"]:.3f})')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Gr√°fico 4: Curva ROC - Treino
    try:
        from sklearn.metrics import roc_curve
        fpr_treino, tpr_treino, _ = roc_curve(y_true_cls_treino, y_pred_cls_treino)
        ax4.plot(fpr_treino, tpr_treino, 'r-', linewidth=2, 
                 label=f'Treino (AUC = {metrics["auc_treino"]:.3f})')
        ax4.plot([0, 1], [0, 1], 'k--', alpha=0.5)
        ax4.set_xlabel('False Positive Rate')
        ax4.set_ylabel('True Positive Rate')
        ax4.set_title('Curva ROC - Treino')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
    except Exception as e:
        ax4.text(0.5, 0.5, f'ROC n√£o dispon√≠vel\n{str(e)}', 
                ha='center', va='center', transform=ax4.transAxes)
        ax4.set_title('Curva ROC - Treino')
    
    # Gr√°fico 5: Curva ROC - Futuro
    try:
        fpr_futuro, tpr_futuro, _ = roc_curve(y_true_cls_futuro, y_pred_cls_futuro)
        ax5.plot(fpr_futuro, tpr_futuro, 'b-', linewidth=2, 
                 label=f'Futuro (AUC = {metrics["auc_futuro"]:.3f})')
        ax5.plot([0, 1], [0, 1], 'k--', alpha=0.5)
        ax5.set_xlabel('False Positive Rate')
        ax5.set_ylabel('True Positive Rate')
        ax5.set_title('Curva ROC - Futuro')
        ax5.legend()
        ax5.grid(True, alpha=0.3)
    except Exception as e:
        ax5.text(0.5, 0.5, f'ROC n√£o dispon√≠vel\n{str(e)}', 
                ha='center', va='center', transform=ax5.transAxes)
        ax5.set_title('Curva ROC - Futuro')
    
    # Gr√°fico 6: M√©tricas Comparativas (Regress√£o + Classifica√ß√£o)
    metric_names = ['R¬≤ Treino', 'R¬≤ Futuro', 'AUC Treino', 'AUC Futuro', 'Accuracy Treino', 'Accuracy Futuro', 'LogLoss Treino', 'LogLoss Futuro']
    metric_values = [metrics['r2_treino'], metrics['r2_futuro'], 
                    metrics['auc_treino'], metrics['auc_futuro'],
                    metrics['accuracy_treino'], metrics['accuracy_futuro'],
                    metrics['logloss_treino'], metrics['logloss_futuro']]
    colors = ['#4ECDC4', '#FF6B6B', '#45B7D1', '#F39C12', '#9B59B6', '#E67E22', '#2ECC71', '#E74C3C']
    
    bars = ax6.bar(metric_names, metric_values, color=colors, alpha=0.7)
    ax6.set_ylabel('Valor')
    ax6.set_title('M√©tricas Comparativas (Regress√£o + Classifica√ß√£o)')
    ax6.grid(True, alpha=0.3, axis='y')
    ax6.tick_params(axis='x', rotation=45)
    
    # Adicionar valores nas barras
    for bar, valor in zip(bars, metric_values):
        ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{valor:.3f}', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    
    # Salvar gr√°fico
    nome_arquivo = "resultados_dkt.png"
    caminho = os.path.join(pasta_saida, nome_arquivo)
    plt.savefig(caminho, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"   üìä Gr√°ficos salvos em: {caminho}")

def salvar_metricas(metrics: Dict[str, float], losses: List[float], 
                   pasta_saida: str = "resultados_dkt"):
    """
    Salva m√©tricas e resultados
    """
    # Converter valores numpy para float para serializa√ß√£o JSON
    metrics_serializable = {}
    for key, value in metrics.items():
        if hasattr(value, 'item'):  # Se √© numpy type
            metrics_serializable[key] = float(value.item())
        else:
            metrics_serializable[key] = float(value)
    
    resultados = {
        'metrics': metrics_serializable,
        'final_loss': float(losses[-1]) if losses else 0.0,
        'training_losses': [float(loss) for loss in losses],
        'model_config': {
            'input_size': 4,
            'hidden_size': 64,
            'num_layers': 2,
            'learning_rate': 0.001,
            'epochs': 100
        }
    }
    
    nome_arquivo = "metricas_dkt.json"
    caminho = os.path.join(pasta_saida, nome_arquivo)
    
    with open(caminho, 'w', encoding='utf-8') as f:
        json.dump(resultados, f, indent=2, ensure_ascii=False)
    
    print(f"   üìÑ M√©tricas salvas em: {caminho}")

def salvar_modelo(model: DKTModel, pasta_saida: str = "resultados_dkt"):
    """
    Salva o modelo treinado
    """
    nome_arquivo = "modelo_dkt.pth"
    caminho = os.path.join(pasta_saida, nome_arquivo)
    
    torch.save(model.state_dict(), caminho)
    print(f"   üíæ Modelo salvo em: {caminho}")

def main():
    parser = argparse.ArgumentParser(description='DKT multitarefa com LSTM para prever desempenho (regress√£o) e acerto (classifica√ß√£o)')
    parser.add_argument('student_id', type=int, help='ID do aluno')
    parser.add_argument('--dias', type=int, default=20, help='N√∫mero de dias (padr√£o: 20)')
    parser.add_argument('--window-size', type=int, default=5, help='Tamanho da janela temporal (padr√£o: 5)')
    parser.add_argument('--hidden-size', type=int, default=64, help='Tamanho da camada oculta (padr√£o: 64)')
    parser.add_argument('--num-layers', type=int, default=2, help='N√∫mero de camadas LSTM (padr√£o: 2)')
    parser.add_argument('--learning-rate', type=float, default=0.001, help='Taxa de aprendizado (padr√£o: 0.001)')
    parser.add_argument('--epochs', type=int, default=100, help='N√∫mero de √©pocas (padr√£o: 100)')
    parser.add_argument('--batch-size', type=int, default=8, help='Tamanho do batch (padr√£o: 8)')
    parser.add_argument('--pasta-saida', default='resultados_dkt', help='Pasta para salvar resultados')
    parser.add_argument('--patience', type=int, default=10, help='Patience para early stopping (padr√£o: 10)')
    parser.add_argument('--val-split', type=float, default=0.2, help='Propor√ß√£o de valida√ß√£o (padr√£o: 0.2)')
    parser.add_argument('--alpha', type=float, default=1.0, help='Peso da perda de classifica√ß√£o (padr√£o: 1.0)')
    parser.add_argument('--beta', type=float, default=0.7, help='Peso da perda de regress√£o (padr√£o: 0.7)')
    parser.add_argument('--no-calibracao', action='store_true', help='Desabilitar calibra√ß√£o')
    parser.add_argument('--no-normalizacao', action='store_true', help='Desabilitar normaliza√ß√£o')
    
    args = parser.parse_args()
    
    print("üß† DKT MULTITAREFA COM LSTM - REGRESS√ÉO + CLASSIFICA√á√ÉO")
    print("=" * 50)
    print(f"üë§ Aluno: {args.student_id}")
    print(f"üìÖ Dias: {args.dias}")
    print(f"ü™ü Janela temporal: {args.window_size}")
    print(f"üß† Hidden size: {args.hidden_size}")
    print(f"üìö Camadas LSTM: {args.num_layers}")
    print(f"üìà Learning rate: {args.learning_rate}")
    print(f"üîÑ √âpocas: {args.epochs}")
    print(f"üì¶ Batch size: {args.batch_size}")
    
    try:
        # 1. Carregar dados do aluno
        dados = carregar_dados_aluno(args.student_id, args.dias)
        
        # 2. Preparar dados para DKT (65 dias total, treino com 60, teste com 5)
        sequences_treino, targets_reg_treino, targets_cls_treino, features_teste, targets_reg_teste, targets_cls_teste, normalizacao_stats = preparar_dados_dkt(
            dados, args.window_size, dias_treino=60, normalizar=not args.no_normalizacao
        )
        
        if len(sequences_treino) < 2:
            print("‚ùå Dados insuficientes para treinamento!")
            return
        
        # 3. Treinar modelo
        model, losses = treinar_modelo_dkt(
            sequences_treino, targets_reg_treino, targets_cls_treino,
            input_size=4,
            hidden_size=args.hidden_size,
            num_layers=args.num_layers,
            learning_rate=args.learning_rate,
            epochs=args.epochs,
            batch_size=args.batch_size,
            alpha=args.alpha, beta=args.beta,
            patience=args.patience, val_split=args.val_split
        )
        
        # 4. Avaliar modelo e fazer previs√µes futuras
        metrics, y_pred_reg_treino, y_true_reg_treino, y_pred_cls_treino, y_true_cls_treino, y_pred_reg_futuro, y_true_reg_futuro, y_pred_cls_futuro, y_true_cls_futuro = avaliar_modelo_dkt(
            model, sequences_treino, targets_reg_treino, targets_cls_treino, features_teste, targets_reg_teste, targets_cls_teste, args.batch_size, calibrar=not args.no_calibracao
        )
        
        # 5. Plotar resultados
        plotar_resultados(losses, y_pred_reg_treino, y_true_reg_treino, y_pred_cls_treino, y_true_cls_treino,
                         y_pred_reg_futuro, y_true_reg_futuro, y_pred_cls_futuro, y_true_cls_futuro, metrics, args.pasta_saida)
        
        # 6. Salvar m√©tricas e modelo
        salvar_metricas(metrics, losses, args.pasta_saida)
        salvar_modelo(model, args.pasta_saida)
        
        print(f"\nüéâ DKT conclu√≠do com sucesso!")
        print(f"üìÅ Resultados salvos em: {args.pasta_saida}")
        print(f"üìä M√©tricas finais:")
        print(f"   üìà REGRESS√ÉO - Treino: MSE={metrics['mse_treino']:.4f}, MAE={metrics['mae_treino']:.4f}, R¬≤={metrics['r2_treino']:.4f}")
        print(f"   üîÆ REGRESS√ÉO - Futuro: MSE={metrics['mse_futuro']:.4f}, MAE={metrics['mae_futuro']:.4f}, R¬≤={metrics['r2_futuro']:.4f}")
        print(f"   üéØ CLASSIFICA√á√ÉO - Treino: AUC={metrics['auc_treino']:.4f}, Accuracy={metrics['accuracy_treino']:.4f}, LogLoss={metrics['logloss_treino']:.4f}")
        print(f"   üéØ CLASSIFICA√á√ÉO - Futuro: AUC={metrics['auc_futuro']:.4f}, Accuracy={metrics['accuracy_futuro']:.4f}, LogLoss={metrics['logloss_futuro']:.4f}")
        
    except Exception as e:
        print(f"‚ùå Erro durante execu√ß√£o: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 